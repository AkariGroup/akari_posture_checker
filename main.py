#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""DepthAI + MediaPipe Pose ã§å§¿å‹¢ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†å®Œå…¨ç‰ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆé–¢æ•°åŒ–ç‰ˆãƒ»ä¿®æ­£æ¸ˆã¿ï¼‰
æ©Ÿèƒ½1. å·¦å³è‡ªå‹•åˆ¤å®šã§é¼»â€è‚©â€è…°ãƒ»è†â€è…°â€è‚©ã®è§’åº¦ã‚’è¨ˆç®—
2. çŒ«èƒŒã‚’ 3 å›æ¤œçŸ¥ã™ã‚‹ã¨ siren_long.wav ã‚’ãƒ«ãƒ¼ãƒ—å†ç”Ÿã—ç¶šã‘ã‚‹ â˜…EDIT
3. ç«‹ã¡å§¿å‹¢ã¸å¤‰åŒ–ã—ãŸç¬é–“ã ã‘ã‚µã‚¦ãƒ³ãƒ‰ã‚’å†ç”Ÿï¼ˆreset.wavï¼‰
4. 1æ™‚é–“ä»¥ä¸Šé€£ç¶šç€åº§ã™ã‚‹ã¨ã€ŒStretch Time!ã€ã‚’ç”»é¢ã«è¡¨ç¤ºã—ã¦ siren_long.wav ã‚’ãƒ«ãƒ¼ãƒ—å†ç”Ÿ
5. äººç‰©ãŒæ¤œå‡ºã•ã‚Œãªã„é–“ã¯ã‚¿ã‚¤ãƒãƒ¼ã¨ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
6. å³ä¸‹ã«åº§ã‚Šã‚¿ã‚¤ãƒãƒ¼ï¼ˆHH:MM:SSï¼‰ã‚’å¸¸æ™‚è¡¨ç¤º"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import sys
import math
import time
import cv2
import mediapipe as mp
import depthai as dai
import absl.logging
from playsound import playsound
from akari_client import AkariClient
import threading

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  MediaPipe Pose ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mp_drawing = mp.solutions.drawing_utils
mp_pose    = mp.solutions.pose

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  å®šæ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
POSTURE_THRESHOLD   = 130         # çŒ«èƒŒåˆ¤å®šï¼ˆé¼»â€è‚©â€è…°ï¼‰
STAND_THRESHOLD     = 170         # ç«‹ã¡å§¿å‹¢åˆ¤å®šï¼ˆè†â€è…°â€è‚©ï¼‰
MAX_COUNTER         =   3         # çŒ«èƒŒè¨±å®¹å›æ•°
DETECTION_COOLDOWN  =   5.0       # çŒ«èƒŒã‚µã‚¦ãƒ³ãƒ‰ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ [s]
VIS_THRESH          =   0.5       # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ visibility ã—ãã„å€¤
SIT_LIMIT_SEC       = 3600          # 1æ™‚é–“ä»¥ä¸Šã®é€£ç¶šç€åº§ã§ã‚¹ãƒˆãƒ¬ãƒƒãƒä¿ƒã—

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ãƒ«ãƒ¼ãƒ—éŸ³å†ç”Ÿç”¨é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def play_ping_loop(state):
    """ siren_long.wav ã‚’ãƒ«ãƒ¼ãƒ—å†ç”Ÿã™ã‚‹ãŸã‚ã®ã‚¹ãƒ¬ãƒƒãƒ‰é–¢æ•° """
    while state['ping_active']:
        playsound("sound/siren_long.wav")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ç¾¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calculate_angle(a, b, c):
    """ 3ç‚¹ã®åº§æ¨™ã‹ã‚‰è§’åº¦ã‚’è¨ˆç®—ã™ã‚‹ """
    ang = math.degrees(
        math.atan2(c[1]-b[1], c[0]-b[0]) -
        math.atan2(a[1]-b[1], a[0]-b[0])
    )
    return abs(ang if ang < 180 else 360-ang)

def get_angle(i, j, k, lms, v=VIS_THRESH):
    """ ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰è§’åº¦ã‚’å–å¾—ã™ã‚‹ """
    try:
        la, lb, lc = lms[i], lms[j], lms[k]
    except IndexError:
        return 0.0
    if min(la.visibility, lb.visibility, lc.visibility) < v:
        return 0.0
    return calculate_angle([la.x,la.y], [lb.x,lb.y], [lc.x,lc.y])

def choose_side(lms, v=VIS_THRESH):
    """ å¯è¦–æ€§ã‚„æ·±åº¦ã‹ã‚‰ã€ä½“ã®ã©ã¡ã‚‰å´ã‚’å‘ã„ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ """
    Ls, Rs = lms[mp_pose.PoseLandmark.LEFT_SHOULDER.value],  lms[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]
    Lh, Rh = lms[mp_pose.PoseLandmark.LEFT_HIP.value],        lms[mp_pose.PoseLandmark.RIGHT_HIP.value]
    vis_left  = Ls.visibility + Lh.visibility
    vis_right = Rs.visibility + Rh.visibility
    if vis_left  >= v*2 and vis_left  > vis_right: return 'left'
    if vis_right >= v*2 and vis_right > vis_left: return 'right'
    if Ls.z < Rs.z: return 'left'
    if Rs.z < Ls.z: return 'right'
    nose = lms[mp_pose.PoseLandmark.NOSE.value]
    dL = (nose.x-Ls.x)**2 + (nose.y-Ls.y)**2
    dR = (nose.x-Rs.x)**2 + (nose.y-Rs.y)**2
    return 'left' if dL < dR else 'right'

def draw_text(img, text, pos, col=(255,255,255), bg=(0,0,0)):
    """ èƒŒæ™¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’æç”»ã™ã‚‹ """
    font, scale, th = cv2.FONT_HERSHEY_SIMPLEX, 1.0, 3
    sz = cv2.getTextSize(text, font, scale, th)[0]; x, y = pos
    cv2.rectangle(img, (x-10, y-sz[1]-10), (x+sz[0]+10, y+10), bg, -1)
    cv2.putText(img, text, (x, y), font, scale, col, th)

def hms(sec):
    """ ç§’æ•°ã‚’ HH:MM:SS å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹ """
    return f"{int(sec//3600):02d}:{int(sec%3600//60):02d}:{int(sec%60):02d}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  åˆæœŸåŒ–é–¢æ•°ç¾¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def initialize_akari():
    """ Akari ãƒ­ãƒœãƒƒãƒˆã‚’åˆæœŸåŒ–ã—ã€æ¥ç¶šã™ã‚‹ """
    print("ğŸ¤–  Akari ãƒ­ãƒœãƒƒãƒˆã¨æ¥ç¶šã—ã¦ã„ã¾ã™ ...")
    akari = AkariClient()
    joints = akari.joints
    joints.enable_all_servo()
    print("ğŸŒ€  ã‚«ãƒ¡ãƒ©ã®é ­éƒ¨ã‚’åˆæœŸä½ç½®ã¸ï¼ˆpan=0, tilt=0ï¼‰")
    joints.move_joint_positions(sync=True, pan=0, tilt=0)
    return akari

def suppress_logs():
    """ TensorFlow ã¨ MediaPipe ã®å†—é•·ãªãƒ­ã‚°å‡ºåŠ›ã‚’æŠ‘åˆ¶ã™ã‚‹ """
    absl.logging.set_verbosity(absl.logging.ERROR)
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
    try:
        devnull_fd = os.open(os.devnull, os.O_WRONLY)
        os.dup2(devnull_fd, sys.stderr.fileno())
    except Exception:
        pass

def setup_depthai_pipeline():
    """ DepthAI ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ """
    pipeline = dai.Pipeline()
    cam = pipeline.createColorCamera()
    cam.setPreviewSize(640, 480)
    cam.setInterleaved(False)
    cam.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)
    xout = pipeline.createXLinkOut()
    xout.setStreamName("rgb")
    cam.preview.link(xout.input)
    return pipeline

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  çŠ¶æ…‹ç®¡ç†ãƒ»æ›´æ–°é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def manage_sound_loop(state, should_be_active):
    """ ã‚µã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ—ã®çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹ï¼ˆé–‹å§‹ãƒ»åœæ­¢ï¼‰ """
    if should_be_active and not state['ping_active']:
        state['ping_active'] = True
        state['ping_thread'] = threading.Thread(target=play_ping_loop, args=(state,), daemon=True)
        state['ping_thread'].start()
    elif not should_be_active and state['ping_active']:
        state['ping_active'] = False
        if state['ping_thread']:
            state['ping_thread'].join()
            state['ping_thread'] = None
    return state

def process_landmarks(img, pose_landmarks, state): # <- å¤‰æ›´ç‚¹: å¼•æ•°ã‚’ `lms` ã‹ã‚‰ `pose_landmarks` ã«å¤‰æ›´
    """ æ¤œå‡ºã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å‡¦ç†ã—ã€å§¿å‹¢ã‚’åˆ¤å®šãƒ»æç”»ã™ã‚‹ """
    lms = pose_landmarks.landmark # <- å¤‰æ›´ç‚¹: æç”»ã§ä½¿ã†è¦ªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰åº§æ¨™ãƒªã‚¹ãƒˆã‚’æŠ½å‡º

    now = time.time()
    side = choose_side(lms)

    # è§’åº¦è¨ˆç®—
    sit_angle_points = (
        mp_pose.PoseLandmark.NOSE.value,
        mp_pose.PoseLandmark.RIGHT_SHOULDER.value if side=='right' else mp_pose.PoseLandmark.LEFT_SHOULDER.value,
        mp_pose.PoseLandmark.RIGHT_HIP.value if side=='right' else mp_pose.PoseLandmark.LEFT_HIP.value,
    )
    stand_angle_points = (
        mp_pose.PoseLandmark.RIGHT_KNEE.value if side=='right' else mp_pose.PoseLandmark.LEFT_KNEE.value,
        mp_pose.PoseLandmark.RIGHT_HIP.value if side=='right' else mp_pose.PoseLandmark.LEFT_HIP.value,
        mp_pose.PoseLandmark.RIGHT_SHOULDER.value if side=='right' else mp_pose.PoseLandmark.LEFT_SHOULDER.value,
    )
    sit = get_angle(*sit_angle_points, lms)
    std = get_angle(*stand_angle_points, lms)
    if std > 180:
        std = 360 - std

    # å§¿å‹¢åˆ¤å®š
    is_stand = std >= STAND_THRESHOLD
    is_sit = sit != 0 and not is_stand

    # ç€åº§ã‚¿ã‚¤ãƒãƒ¼
    if is_sit and state['sitting_start_time'] is None:
        state['sitting_start_time'], state['stretch_prompted'] = now, False
    if is_stand:
        state['sitting_start_time'], state['stretch_prompted'] = None, False

    # ç«‹ã¡å§¿å‹¢ã¸ã®é·ç§»ã‚’æ¤œå‡º
    if is_stand and not state['prev_is_standing']:
        playsound("sound/reset.wav")
        state['stand_up_time'] = now
        state['bad_posture_count'] = 0

    # çŒ«èƒŒåˆ¤å®š
    if state['stand_up_time'] and now - state['stand_up_time'] < 10:
        draw_text(img, "Posture Check Paused", (10,70), (255,255,255), (90,90,90))
    else:
        if sit < POSTURE_THRESHOLD and sit != 0:
            state['consecutive_bad_posture'] += 1
            if state['consecutive_bad_posture'] >= 3 and now - state['last_detection_time'] >= DETECTION_COOLDOWN:
                state['bad_posture_count'] += 1
                state['last_detection_time'] = now
                playsound("sound/siren_short.wav")
                state['consecutive_bad_posture'] = 0
            draw_text(img, f"Bad Posture! count:{state['bad_posture_count']}", (10,70), (255,255,255), (0,0,200))
        else:
            state['consecutive_bad_posture'] = 0
            if is_stand:
                draw_text(img, "Standing!", (10,70), (255,255,255), (150,0,0))
            else:
                draw_text(img, f"Good Posture! count:{state['bad_posture_count']}", (10,70), (255,255,255), (0,150,0))

    # Stretch Time åˆ¤å®š
    is_stretch_time = is_sit and state['sitting_start_time'] and now - state['sitting_start_time'] >= SIT_LIMIT_SEC
    if is_stretch_time:
        if not state['stretch_prompted']:
            print("ğŸ§˜  1æ™‚é–“ä»¥ä¸Šåº§ã‚Šç¶šã‘ã¦ã„ã¾ã™ã€‚ã‚¹ãƒˆãƒ¬ãƒƒãƒã—ã¾ã—ã‚‡ã†ï¼")
            state['stretch_prompted'] = True
        draw_text(img, "Stretch Time!", (10,110), (0,0,0), (0,255,255))
    # bad_posture 3 å›è¶…éå‡¦ç† â˜…EDIT
    is_bad_posture_exceeded = state['bad_posture_count'] >= MAX_COUNTER
    if is_bad_posture_exceeded:
        if not state['ping_active']:
            print("âš ï¸  çŒ«èƒŒãŒ 3 å›é€£ç¶šã§æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚æ­£ã—ã„å§¿å‹¢ã«æˆ»ã—ã¦ãã ã•ã„ï¼")
        draw_text(img, "    PLEASE STRETCH    ", (10,110), (0,0,0), (0,0,255))

    # ã‚µã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ—ã®åˆ¶å¾¡
    should_ping = is_stretch_time or is_bad_posture_exceeded
    state = manage_sound_loop(state, should_ping)
    
    # è§’åº¦ã¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»
    draw_text(img, f"{side[0].upper()}-deg1:{'N/A' if sit==0 else int(sit)}", (400,70), (20,20,20), (200,200,200) if sit==0 else (250,250,250))
    draw_text(img, f"{side[0].upper()}-deg2:{'N/A' if std==0 else int(std)}", (400,110), (20,20,20), (200,200,200) if std==0 else (250,250,250))
    mp_drawing.draw_landmarks(img, pose_landmarks, mp_pose.POSE_CONNECTIONS) # <- å¤‰æ›´ç‚¹: `res.pose_landmarks` ã‚’ `pose_landmarks` ã«å¤‰æ›´
    
    state['prev_is_standing'] = is_stand
    return state

def handle_no_detection(img, state):
    """ äººç‰©ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã®å‡¦ç† """
    draw_text(img, "No detection", (10,70), (200,200,200), (150,0,0))
    # çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    state['sitting_start_time'] = None
    state['stretch_prompted'] = False
    state['consecutive_bad_posture'] = 0
    state['prev_is_standing'] = False
    # ã‚µã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ—ã‚’åœæ­¢
    state = manage_sound_loop(state, False)
    return state

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ãƒ¡ã‚¤ãƒ³é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    """ ãƒ¡ã‚¤ãƒ³å‡¦ç† """
    # åˆæœŸåŒ–
    # initialize_akari()
    suppress_logs()
    pipeline = setup_depthai_pipeline()

    # çŠ¶æ…‹å¤‰æ•°ã‚’è¾æ›¸ã§ç®¡ç†
    state = {
        'bad_posture_count': 0,
        'consecutive_bad_posture': 0,
        'last_detection_time': 0.0,
        'sitting_start_time': None,
        'stretch_prompted': False,
        'prev_is_standing': False,
        'stand_up_time': None,
        'ping_thread': None,
        'ping_active': False
    }

    print("ğŸ“·  DepthAI ã‚«ãƒ¡ãƒ©èµ·å‹•ä¸­ã€‚'q' ã§çµ‚äº†")
    
    with dai.Device(pipeline) as device, mp_pose.Pose(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as pose:

        rgb_queue = device.getOutputQueue("rgb", maxSize=4, blocking=False)

        while True:
            in_rgb = rgb_queue.tryGet()
            if in_rgb is None:
                cv2.waitKey(1)
                continue

            frame = in_rgb.getCvFrame()
            if frame is None:
                continue
                
            # MediaPipeã§ã®å‡¦ç†
            imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            imgRGB.flags.writeable = False
            results = pose.process(imgRGB)
            imgRGB.flags.writeable = True
            img = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2BGR)

            # å§¿å‹¢ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚ŒãŸã‹ã©ã†ã‹ã§å‡¦ç†ã‚’åˆ†å²
            if results.pose_landmarks:
                state = process_landmarks(img, results.pose_landmarks, state) # <- å¤‰æ›´ç‚¹: `.landmark` ã‚’ä»˜ã‘ãšã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’æ¸¡ã™
            else:
                state = handle_no_detection(img, state)

            # ã‚¿ã‚¤ãƒãƒ¼ã‚’å¸¸æ™‚è¡¨ç¤º
            h, w, _ = img.shape
            if state['sitting_start_time']:
                elapsed = time.time() - state['sitting_start_time']
                draw_text(img, f"Sitting {hms(elapsed)}", (w-270, h-20), (0,0,0), (255,255,255))
            else:
                draw_text(img, "Standing 00:00:00", (w-270, h-20), (0,0,0), (255,255,255))
            
            # ç”»é¢è¡¨ç¤ºã¨çµ‚äº†å‡¦ç†
            cv2.imshow("Posture Checker", img)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    # çµ‚äº†å‡¦ç†
    state = manage_sound_loop(state, False)
    cv2.destroyAllWindows()
    print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†")

if __name__ == '__main__':
    main()